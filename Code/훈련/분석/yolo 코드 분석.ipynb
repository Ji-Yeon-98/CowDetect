{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPevE9R+D+6PXDP9PD3apJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1. yolov5"],"metadata":{"id":"hp3dDshsbIgz"}},{"cell_type":"markdown","source":["https://github.com/jks5177/Yolov5_DeepSort_Pytorch.git의 track.py 코드 분석"],"metadata":{"id":"EXhtcVREanqx"}},{"cell_type":"markdown","metadata":{"id":"2Y6IQM9qU6on"},"source":["## 한글 깨짐 현생 해결\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7325,"status":"ok","timestamp":1647518724204,"user":{"displayName":"추지연","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02625041978526659436"},"user_tz":-540},"id":"FVldSssVU9Du","outputId":"ee64c44e-2401-4999-82cd-548af68ce8b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 9,604 kB of archives.\n","After this operation, 29.5 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n","Fetched 9,604 kB in 0s (44.8 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 155335 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n","Unpacking fonts-nanum (20170925-1) ...\n","Setting up fonts-nanum (20170925-1) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n"]}],"source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"]},{"cell_type":"markdown","metadata":{"id":"Ll6wIk5Iyna5"},"source":["## git clone 하기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18137,"status":"ok","timestamp":1647518742327,"user":{"displayName":"추지연","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02625041978526659436"},"user_tz":-540},"id":"SWbp-RjlyLf7","outputId":"a80d7a93-1cfc-439d-d7d1-1ef71b008957"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Yolov5_DeepSort_Pytorch'...\n","remote: Enumerating objects: 898, done.\u001b[K\n","remote: Total 898 (delta 0), reused 0 (delta 0), pack-reused 898\u001b[K\n","Receiving objects: 100% (898/898), 70.82 MiB | 15.21 MiB/s, done.\n","Resolving deltas: 100% (414/414), done.\n","Submodule 'yolov5' (https://github.com/ultralytics/yolov5.git) registered for path 'yolov5'\n","Cloning into '/content/Yolov5_DeepSort_Pytorch/yolov5'...\n","remote: Enumerating objects: 11367, done.        \n","remote: Total 11367 (delta 0), reused 0 (delta 0), pack-reused 11367        \n","Receiving objects: 100% (11367/11367), 11.28 MiB | 29.76 MiB/s, done.\n","Resolving deltas: 100% (7847/7847), done.\n","Submodule path 'yolov5': checked out 'b8be76f915207ef0759bfb0f1c0707c79877b763'\n","/content/Yolov5_DeepSort_Pytorch\n","\u001b[K     |████████████████████████████████| 596 kB 14.2 MB/s \n","\u001b[?25h"]}],"source":["!git clone --recurse-submodules https://github.com/jks5177/Yolov5_DeepSort_Pytorch.git\n","\n","%cd Yolov5_DeepSort_Pytorch\n","%pip install -qr requirements.txt\n","\n","import torch\n","from IPython.display import Image, clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2Rd9fz4beeM"},"outputs":[],"source":["%pip install -qr ./yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18280,"status":"ok","timestamp":1647518764075,"user":{"displayName":"추지연","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02625041978526659436"},"user_tz":-540},"id":"Z1vX1n0X0ATo","outputId":"2a7d4d24-b6f0-42c8-8075-78d33211eed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-17 12:05:38--  https://www.dropbox.com/s/x4x6fr88lbgb504/sample_video.mp4\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/x4x6fr88lbgb504/sample_video.mp4 [following]\n","--2022-03-17 12:05:38--  https://www.dropbox.com/s/raw/x4x6fr88lbgb504/sample_video.mp4\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com/cd/0/inline/BhosIChN_GOH2ImBp7kOWyetoQtQOMdRCdXo-XX2PHZVWnnLmy_MBQl0ifFQakoBi7m9xMXzdLTQJ3TKsJj3vHam-I6UAd2bXbQOzV9FFbsX7JTiJqpHX1iJNJzWgyB3toX0Mnqo5Ppwjs7WFQhl30Ra3oYm8e5GUQBmrKkvG1cjtg/file# [following]\n","--2022-03-17 12:05:38--  https://ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com/cd/0/inline/BhosIChN_GOH2ImBp7kOWyetoQtQOMdRCdXo-XX2PHZVWnnLmy_MBQl0ifFQakoBi7m9xMXzdLTQJ3TKsJj3vHam-I6UAd2bXbQOzV9FFbsX7JTiJqpHX1iJNJzWgyB3toX0Mnqo5Ppwjs7WFQhl30Ra3oYm8e5GUQBmrKkvG1cjtg/file\n","Resolving ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com (ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6021:15::a27d:410f\n","Connecting to ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com (ucfd1c7cb812e4ea78c055404dd2.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 299842873 (286M) [video/mp4]\n","Saving to: ‘sample_video.mp4’\n","\n","sample_video.mp4    100%[===================>] 285.95M  17.6MB/s    in 16s     \n","\n","2022-03-17 12:05:56 (17.5 MB/s) - ‘sample_video.mp4’ saved [299842873/299842873]\n","\n"]}],"source":["!wget https://www.dropbox.com/s/x4x6fr88lbgb504/sample_video.mp4"]},{"cell_type":"markdown","metadata":{"id":"gMtGaxfGymtG"},"source":["## YOLOv5 weight 다운로드"]},{"cell_type":"markdown","metadata":{"id":"CsZ3qdJtLf66"},"source":["YOLOv5 weight를 다운로드 받아 사전에 훈련된 파일을 사용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11530,"status":"ok","timestamp":1647518775558,"user":{"displayName":"추지연","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02625041978526659436"},"user_tz":-540},"id":"u8T8R9uPyZdy","outputId":"ffcd4632-aee3-43a3-8d4d-d91095a91400"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-17 12:05:56--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x6.pt\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/99067600-9af3-11eb-9293-d6a57f256760?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220317T120556Z&X-Amz-Expires=300&X-Amz-Signature=2ff8ee290e766448ae467d053319f57d716e0ccaa2117a774cf41d3fbe0c208d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5x6.pt&response-content-type=application%2Foctet-stream [following]\n","--2022-03-17 12:05:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/99067600-9af3-11eb-9293-d6a57f256760?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220317T120556Z&X-Amz-Expires=300&X-Amz-Signature=2ff8ee290e766448ae467d053319f57d716e0ccaa2117a774cf41d3fbe0c208d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5x6.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 284504825 (271M) [application/octet-stream]\n","Saving to: ‘/content/Yolov5_DeepSort_Pytorch/yolov5/weights/yolov5x6.pt’\n","\n","/content/Yolov5_Dee 100%[===================>] 271.32M  23.4MB/s    in 11s     \n","\n","2022-03-17 12:06:07 (25.2 MB/s) - ‘/content/Yolov5_DeepSort_Pytorch/yolov5/weights/yolov5x6.pt’ saved [284504825/284504825]\n","\n"]}],"source":["!wget -nc https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x6.pt -O /content/Yolov5_DeepSort_Pytorch/yolov5/weights/yolov5x6.pt"]},{"cell_type":"markdown","metadata":{"id":"hfowGbwLy0vi"},"source":["## Cow Tracking"]},{"cell_type":"code","source":["import sys\n","\n","sys.path.insert(0, './yolov5')"],"metadata":{"id":"5jre7GaRXfQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from yolov5.utils.google_utils import attempt_download\n","from yolov5.models.experimental import attempt_load\n","from yolov5.utils.datasets import LoadImages, LoadStreams\n","from yolov5.utils.general import check_img_size, non_max_suppression, scale_coords, check_imshow, xyxy2xywh\n","from yolov5.utils.torch_utils import select_device, time_synchronized\n","from yolov5.utils.plots import plot_one_box\n","from deep_sort_pytorch.utils.parser import get_config\n","from deep_sort_pytorch.deep_sort import DeepSort\n","import argparse\n","import os\n","import platform\n","import shutil\n","import time\n","from pathlib import Path\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","import json"],"metadata":{"id":"7CMn2P4wYWNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# id에 따라 고정 색상 추가하는 함수\n","def compute_color_for_id(label):\n","    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n","    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n","    # %225 = RGB 색상\n","    return tuple(color)"],"metadata":{"id":"NcZ6sRstYYCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect(opt):\n","    out, source, yolo_weights, deep_sort_weights, show_vid, save_vid, save_txt, imgsz, evaluate = \\\n","        opt.output, opt.source, opt.yolo_weights, opt.deep_sort_weights, opt.show_vid, opt.save_vid, \\\n","        opt.save_txt, opt.img_size, opt.evaluate\n","    webcam = source == '0' or source.startswith(\n","        'rtsp') or source.startswith('http') or source.endswith('.txt')\n","    # source가 0 or source가 rtsp, http로 시작 or source가 .txt로 끝\n","\n","    # deepsort 초기화\n","    cfg = get_config()\n","    # 최적화 프로그램의 구성을 반환 : 동일한 최적화 프로그램을 나중에(저장된 상태 없이) 다시 인스턴스화\n","    cfg.merge_from_file(opt.config_deepsort)\n","    # config_deepsort 파일을 yaml_파일로 업데이트\n","    # Key, Value (list) 로 구성된 Dictionary 로 YAML 파일을 파싱\n","    attempt_download(deep_sort_weights, repo='mikel-brostrom/Yolov5_DeepSort_Pytorch')\n","    # 'mikel-brostrom/Yolov5_DeepSort_Pytorch'에서 deep_sort 가중치 다운받기\n","    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n","                        max_dist=cfg.DEEPSORT.MAX_DIST, min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n","                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n","                        max_age=cfg.DEEPSORT.MAX_AGE, n_init=cfg.DEEPSORT.N_INIT, nn_budget=cfg.DEEPSORT.NN_BUDGET,\n","                        use_cuda=True)\n","    \n","    # DeepSort 매개변수\n","    # model_path: 들어오는 특징 추출 모델, 네트워크 모델입니다.\n","    # max_dist：NearestNeighborDistanceMetric 매개변수 값\n","    # min_Confidence: 필터 감지 bbox 상자의 분수 값\n","    # nms_max_overlap: 비최대 억제의 매개변수  \n","    # max_iou_distance：NearestNeighborDistanceMetric(“cosine”, max_cosine_distance, nn_budget) 매개변수 값\n","    # max_age: 최대 수명\n","    # n_init: 연속된 여러 프레임에 대해 감지될 때까지 개체가 생성되지 않습니다.\n","    # nn_budget: NearestNeighborDistanceMetric 매개변수 값\n","    # use_cuda: GPU 사용 여부\n","\n","    # 초기화\n","    device = select_device(opt.device)\n","    # 디바이스 선택\n","\n","    # MOT16 평가는 여러 추론 스트림을 병렬로 실행하며 각각은 자체 .txt 파일에 작성합니다.\n","    # 따라서 이 경우 출력 폴더는 복원되지 않습니다.\n","    if not evaluate:\n","    #???\n","        if os.path.exists(out):\n","            pass\n","            shutil.rmtree(out)  # 출력폴더 삭제\n","        os.makedirs(out)  # 새로운 출력폴더 만들기\n","\n","    # 모델 불러오기t\n","    model = attempt_load(yolo_weights, map_location=device)  # FP32 모델 로드\n","    stride = int(model.stride.max())  # ??? stride, 필터를 적용하는 간격\n","    imgsz = check_img_size(imgsz, s=stride)  # 이미지 사이즈를 stride로 나눌 수 있는지 체크\n","    names = model.module.names if hasattr(model, 'module') else model.names  # class name을 설정\n","    # model의 module 속성이 있으면 model.module.names 없으면 model.names\n","\n","    half = device.type != 'cpu'\n","    # CPU를 사용하지 않으면\n","    if half:\n","        model.half()  # 모델 자체를 FP16으로 변환\n","\n","    # Dataloader 설정\n","    vid_path, vid_writer = None, None\n","    # 환경이 이미지 표시를 지원하는지 확인\n","    if show_vid:\n","        show_vid = check_imshow()\n","\n","    if webcam:\n","        cudnn.benchmark = True  # 내장된 cudnn 자동 튜너를 활성화하여, 하드웨어에 맞게 사용할 최상의 알고리즘 찾기 가능\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride) # 데이터세트 불러오기\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz)\n","\n","    # 이름, 색상 가져오기\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","\n","    # 추론하기\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    t0 = time.time()\n","    #???\n","\n","    save_path = str(Path(out))\n","    # 마지막 /와 .사이의 글자 추출\n","    txt_file_name = source.split('/')[-1].split('.')[0]\n","    txt_path = str(Path(out)) + '/' + txt_file_name + '.txt'\n","    \n","    \"\"\" by 성호 : 변수 지정 \"\"\"\n","    activity_volume = {} # 키 : object id, 값 : 활동량 <= 매번 프레임마다 계산 및 저장\n","    position = {} # 키 : object id,  값 : ((중앙 x, 중앙 y), 프레임)\n","    activity_dic = {} # 키 : object id, 값 : 활동량 배열 <= 180 프레임마다 총 합 저장 및 activity_volume 초기화\n","    activity_mean = {} # 키 : 초(프레임/30), 값 : 총 활동량을 평균 소의 수로 나눔\n","    activity_max = {} # 키 : 초(프레임/30), 값 : 총 활동량을 최대 소의 수로 나눔\n","    count_cow = [] # index : 프레임, 값 : 소의 수\n","    \"\"\" 변수 지정 끝 \"\"\"\n","    \n","    # 프레임 들어오기\n","    # dataset 값 추출할 때 인덱스와 원소 반환 프레임 인덱스, (path??, 이미지, im0S??, vid_cap) \n","    for frame_idx, (path, img, im0s, vid_cap) in enumerate(dataset):\n","        # 프레임 10초 동안 지속되었으면\n","        if frame_idx % 10 == 0:\n","            # img 배열에서 torch Tensor 형식으로 변환\n","            img = torch.from_numpy(img).to(device)\n","            # device가 cpu가 아니면 이미지를 반 값으로 나눈다.\n","            # device가 cpu인 경우에는 이미지 배열을 실수형으로 변경\n","            img = img.half() if half else img.float()  \n","            # uint8 to fp16/32\n","            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","            # 이미지 차원이 3차원인 경우 (ndimension() : 차원)\n","            if img.ndimension() == 3:\n","                # 이미지의 첫번째 차원에 1인 차원 추가 ((unsqueeze(x) = unsqueeze 함수는 텐서 x의 차원 늘림))\n","                # torch 모델의 입력은 항상 배치형태로 받기 때문에 맨 앞에 차원을 하나 넣어주게됩니다\n","                img = img.unsqueeze(0)\n","\n","            # 추론\n","            # 시간 동기화\n","            t1 = time_synchronized()\n","            # model에 이미지를 입력해 예측 (augment : 원본에서 새로운 훈련 샘플 생성하는 기술)\n","            pred = model(img, augment=opt.augment)[0]\n","            \n","           # NMS 적용\n","           # NMS : object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법\n","           # conf_thres와 iou_thres는 모델 prediction이후 바운딩 박스를 조절하는 NMS(Non-Max-Suppresion)에 사용되는 임계값\n","           # agnostic는 Classification없이 물체의 바운딩 박스만을 찾고 싶을때 사용\n","           pred = non_max_suppression(\n","                pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n","            # 시간 동기화\n","            t2 = time_synchronized()\n","\n","            # 프로세스 감지\n","            # 예측값 추출할때 원소 반환 (i??, det???)\n","            for i, det in enumerate(pred):  # 이미지 당 감지\n","                if webcam:  # batch_size >= 1\n","                    p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n","                else:\n","                    p, s, im0 = path, '', im0s\n","\n","                s += '%gx%g ' % img.shape[2:]  # string 출력\n","                save_path = str(Path(out) / Path(p).name)\n","\n","                if det is not None and len(det):\n","                    # img0으로 상자 크기 조정\n","                    det[:, :4] = scale_coords(\n","                        img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                    # 결과 출력\n","                    for c in det[:, -1].unique():\n","                        n = (det[:, -1] == c).sum()  # 클래스 당 감지\n","                        s += '%g %ss, ' % (n, names[int(c)])  # string 추가\n","                    count_cow.append(n) # 소의 마리 수를 저장\n","                    xywhs = xyxy2xywh(det[:, 0:4])\n","                    confs = det[:, 4]\n","                    clss = det[:, 5]\n","\n","                    # pass detections to deepsort\n","                    outputs = deepsort.update(xywhs.cpu(), confs.cpu(), clss, im0)\n","\n","                    # 시각화 위한 draw 상자\n","                    if len(outputs) > 0:\n","                        for j, (output, conf) in enumerate(zip(outputs, confs)):\n","\n","                            bboxes = output[0:4]\n","                            id = output[4]\n","                            cls = output[5]\n","\n","                            c = int(cls)  # integer class\n","                            label = f'{id} {names[c]} {conf:.2f}'\n","                            color = compute_color_for_id(id)\n","                            plot_one_box(bboxes, im0, label=label, color=color, line_thickness=2)\n","\n","                            \"\"\"by 성호 : 소의 활동량을 activity_volume에 저장\"\"\"\n","                            # output[i] : i 짝수일 경우 = x, i 홀수일 경우 = y\n","                            center_x = output[0] + (output[2] - output[0]) / 2 # x의 중앙값\n","                            center_y = output[1] + (output[3] - output[1]) / 2 # y의 중앙값\n","                            # cv2.line(이미지 파일, 시작점 좌표(x,y), 종료 점 좌표, 색상, 선 두께) : 두 좌표를 잇는 선 그리기\n","                            cv2.line(im0, (int(center_x), int(center_y)), (int(center_x), int(center_y)), color, 5) # 가운데 점 표시\n","                            # 객체 이름 : 객체 클래스와 id 붙여서 만들기\n","                            object_name = names[c] + \"_\" + str(id)  # class_name 수정\n","                            # 객체 이름이 전에 저장되어 있다면\n","                            if object_name in activity_volume.keys(): # 이전에 activity_volume에 저장된 값이 있으면\n","                                # 그 객체의 ((중앙 x, 중앙 y), 프레임) 값 불러오기\n","                                x, y, z = position[object_name] # 해당 객체의 중앙값과 프레임 값 불러오기\n","                                \n","                                # 현재 중앙값이 이전 중앙 값보다 오른쪽, 왼쪽, 위, 아래로 50pixel이 넘어가면 움직임으로 감지해 활동량과 위치값 수정\n","                                if center_x > x + 50 or center_x < x - 50 or center_y > y + 50 or center_y < y - 50: \n","                                    # activity_volume(활동량 저장 백터) += ((현재 x 중앙값 - 이전 x 중앙값)/ ((현재 프레임 id - 이전 프레임 id)/30)^2) \n","                                    #                                      + (현재 y 중앙값 - 이전 y 중앙값)/ ((현재 프레임 id - 이전 프레임 id)/30)^2)\n","                                    # ((현재 프레임 id - 이전 프레임 id)/30) = 1초 동안의 frame\n","                                    # **2는 왜..??\n","                                    activity_volume[object_name] += (((center_x - x) / ((frame_idx - z) / 30)) ** 2 + (\n","                                            (center_y - y) / ((frame_idx - z) / 30)) ** 2) ** 0.5\n","                                    # 객체의 ((중앙 x, 중앙 y), 프레임) 값 수정\n","                                    position[object_name] = (int(center_x), int(center_y), int(frame_idx)) # position 값 수정\n","                            else: # 새로운 id가 감지됐으면\n","                                # 객체의 ((중앙 x, 중앙 y), 프레임) 값 넣음\n","                                position[object_name] = (int(center_x), int(center_y), int(frame_idx))\n","                                # 새로운 객체이므로 활동량 0\n","                                activity_volume[object_name] = 0\n","                            \"\"\"add code end\"\"\"\n","\n","                            if save_txt:\n","                                # to MOT format\n","                                bbox_left = output[0]\n","                                bbox_top = output[1]\n","                                bbox_w = output[2] - output[0]\n","                                bbox_h = output[3] - output[1]\n","                                # Write MOT compliant results to file\n","                                with open(txt_path, 'a') as f:\n","                                    f.write(('%g ' * 10 + '\\n') % (frame_idx, id, bbox_left,\n","                                                                   bbox_top, bbox_w, bbox_h, -1, -1, -1,\n","                                                                   -1))  # label format\n","\n","                        \"\"\"by 성호 : 180frame(약 6초) 동안 활동량 계산\"\"\"\n","                        # 프레임이 6초 동안 지속되었으면\n","                        if frame_idx % 180 == 0:\n","                            tmp = 0\n","                            # 객체 id를 for문으로 돌려서 각 객체의 id마다\n","                            for i in activity_volume.keys():\n","                                # activity_dic.keys(활동량 배열)에 activity_volume의 id 값이 있으면\n","                                if i in activity_dic.keys():\n","                                    # activity_volume의 값을 activity_dic의 값에 추가 (활동량 업데이트)\n","                                    activity_dic[i].append(activity_volume[i]) \n","                                else: # activity_volume에 새로운 id가 추가되면\n","                                    try: # 기존의 배열이 있을 때\n","                                        activity_dic[i] = [0 for i in range(len(list(activity_dic.values())[0]) - 1)] #??? 이전 시간의 활동량을 0으로 배열 생성\n","                                        activity_dic[i].append(activity_volume[i]) # 현재 활동량을 마지막에 추가\n","                                    except: # 기존 배열이 없고 처음일 때\n","                                        activity_dic[i] = [activity_volume[i]] # 현재 활동량을 가진 배열을  \n","\n","                                tmp += activity_volume[i] # 각 소의 활동량을 더함\n","                                activity_volume[i] = 0 # activity_volume의 활동량 값 0으로 초기화\n","                            activity_mean[(frame_idx / 30)] = tmp / (int(sum(count_cow)) / len(count_cow)) # 평균 소의 수로 활동량을 나눔 #???sum(count_cow)) / len(count_cow)\n","                            activity_max[(frame_idx / 30)] = tmp / int(max(count_cow)) # 최대 소의 수로 활동량을 나눔\n","                        \"\"\"add code end\"\"\"\n","\n","                else:\n","                    deepsort.increment_ages()\n","\n","                # 시간 출력 (inference + NMS)\n","                print('%sDone. (%.3fs)' % (s, t2 - t1))\n","\n","                # 스트림 결과\n","                if show_vid:\n","                    cv2.imshow(p, im0)\n","                    if cv2.waitKey(1) == ord('q'):  # q to quit\n","                        raise StopIteration\n","\n","                # 결과 저장 (image with detections)\n","                if save_vid:\n","                    if vid_path != save_path:  # 새로운 비디오\n","                        vid_path = save_path\n","                        if isinstance(vid_writer, cv2.VideoWriter):\n","                            vid_writer.release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                            save_path += '.mp4'\n","\n","                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer.write(im0)\n","\n","    # add code (save json file)\n","    with open('/content/activity_volume.json', 'w') as f:\n","        json.dump(activity_volume, f)\n","\n","    # add code (save json file)\n","    with open('/content/activity_dic.json', 'w') as f:\n","        json.dump(activity_dic, f)\n","\n","    # add code (save json file)\n","    with open('/content/activity_mean.json', 'w') as f:\n","        json.dump(activity_mean, f)\n","\n","    # add code (save json file)\n","    with open('/content/activity_max.json', 'w') as f:\n","        json.dump(activity_max, f)\n","\n","    if save_txt or save_vid:\n","        print('Results saved to %s' % os.getcwd() + os.sep + out)\n","        if platform == 'darwin':  # MacOS\n","            os.system('open ' + save_path)\n","\n","    print('Done. (%.3fs)' % (time.time() - t0))"],"metadata":{"id":"8igLF4RJYayk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--yolo_weights', type=str, default='yolov5/weights/yolov5x6.pt', help='model.pt path')\n","    parser.add_argument('--deep_sort_weights', type=str, default='deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7',\n","                        help='ckpt.t7 path')\n","    # file/folder, 0 for webcam\n","    parser.add_argument('--source', type=str, default='0', help='source')\n","    parser.add_argument('--output', type=str, default='inference/output', help='output folder')  # output folder\n","    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n","    parser.add_argument('--conf-thres', type=float, default=0.4, help='object confidence threshold')\n","    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n","    parser.add_argument('--fourcc', type=str, default='mp4v', help='output video codec (verify ffmpeg support)')\n","    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n","    parser.add_argument('--show-vid', action='store_true', help='display tracking video results')\n","    parser.add_argument('--save-vid', action='store_true', help='save video tracking results')\n","    parser.add_argument('--save-txt', action='store_true', help='save MOT compliant results to *.txt')\n","    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven\n","    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 16 17')\n","    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n","    parser.add_argument('--augment', action='store_true', help='augmented inference')\n","    parser.add_argument('--evaluate', action='store_true', help='augmented inference')\n","    parser.add_argument(\"--config_deepsort\", type=str, default=\"deep_sort_pytorch/configs/deep_sort.yaml\")\n","    args = parser.parse_args()\n","    args.img_size = check_img_size(args.img_size)\n","\n","    with torch.no_grad():\n","        detect(args)"],"metadata":{"id":"6aHYbnlmZQOk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["darknet/image_opencv.cpp"],"metadata":{"id":"jZo06dtjfolz"}},{"cell_type":"code","source":["extern \"C\" void draw_detections_cv_v3(mat_cv* mat, detection *dets, int num, float thresh, char **names, image **alphabet, int classes, int ext_output)\n","{\n","    try {\n","        # 원본 이미지\n","        cv::Mat *show_img = (cv::Mat*)mat;\n","        int i, j;\n","        # 객체 정확도 넣을 변수 생성\n","        int accur ; //add code(object accuracy)\n","      # 파일 이름 넣을 변수 생성\n","    \tchar img_name[100] ; //add code(file name)\n","\n","        if (!show_img) return;\n","        static int frame_id = 0;\n","        frame_id++;\n","\n","        /*add code(cutting image) start*/\n","      # cv::Mat 객체\n","    \tcv::Mat _image = *show_img ; //원본 프레임 이미지\n","      # 이미지 복사 (원본 프레임 이미지)\n","    \tcv::Mat subImage = _image.clone() ; //original frame image\n","    \t/*add code end*/\n","\n","        for (i = 0; i < num; ++i) {\n","            char labelstr[4096] = { 0 };\n","            int class_id = -1;\n","            for (j = 0; j < classes; ++j) {\n","                # 9글자 비교해 객체 이름이 dont_show이면 0\n","                int show = strncmp(names[j], \"dont_show\", 9);\n","                # 위치의 확률이 thresh보다 크고 객체 이름이 dont_show이면 ????\n","                if (dets[i].prob[j] > thresh && show) {\n","                    # 클래스 아이디가 0보다 작으면\n","                    if (class_id < 0) {\n","                        strcat(labelstr, names[j]);\n","                        class_id = j;\n","                        char buff[20];\n","                        if (dets[i].track_id) {\n","                            sprintf(buff, \" (id: %d)\", dets[i].track_id);\n","                            strcat(labelstr, buff);\n","                        }\n","                        sprintf(buff, \" (%2.0f%%)\", dets[i].prob[j] * 100);\n","                        strcat(labelstr, buff);\n","                        printf(\"%s: %.0f%% \", names[j], dets[i].prob[j] * 100);\n","                        # 객체 정확도\n","                        # ??dets[i].prob[j] (prob : 확률....?)\n","                        accur = dets[i].prob[j] * 100 ; //add code(object accuracy)\n","                  # 객체 이름 버퍼로 출력  \n","            \t\t\tsprintf(img_name, \"%s\", names[j]) ; //add code(object name)\n","                        if (dets[i].track_id) printf(\"(track = %d, sim = %f) \", dets[i].track_id, dets[i].sim);\n","                    }\n","                    else {\n","                        strcat(labelstr, \", \");\n","                        strcat(labelstr, names[j]);\n","                        printf(\", %s: %.0f%% \", names[j], dets[i].prob[j] * 100);\n","                        # 객체 정확도\n","                        accur = dets[i].prob[j] * 100 ; //add code(object accuracy)\n","                  # 객체 이름 버퍼로 출력\n","            \t\t\tsprintf(img_name, \"%s\", names[j]) ; //add code(object name)\n","                    }\n","                }\n","            }\n","            if (class_id >= 0) {\n","                int width = std::max(1.0f, show_img->rows * .002f);\n","\n","                //if(0){\n","                //width = pow(prob, 1./2.)*10+1;\n","                //alphabet = 0;\n","                //}\n","\n","                //printf(\"%d %s: %.0f%%\\n\", i, names[class_id], prob*100);\n","                int offset = class_id * 123457 % classes;\n","                float red = get_color(2, offset, classes);\n","                float green = get_color(1, offset, classes);\n","                float blue = get_color(0, offset, classes);\n","                float rgb[3];\n","\n","                //width = prob*20+2;\n","\n","                rgb[0] = red;\n","                rgb[1] = green;\n","                rgb[2] = blue;\n","                # ??dets[i]\n","                box b = dets[i].bbox;\n","                if (std::isnan(b.w) || std::isinf(b.w)) b.w = 0.5;\n","                if (std::isnan(b.h) || std::isinf(b.h)) b.h = 0.5;\n","                if (std::isnan(b.x) || std::isinf(b.x)) b.x = 0.5;\n","                if (std::isnan(b.y) || std::isinf(b.y)) b.y = 0.5;\n","                # b.w가 1보다 작으면 b.w 크기, 아니면 1\n","                b.w = (b.w < 1) ? b.w : 1;\n","                b.h = (b.h < 1) ? b.h : 1;\n","                b.x = (b.x < 1) ? b.x : 1;\n","                b.y = (b.y < 1) ? b.y : 1;\n","                //printf(\"%f %f %f %f\\n\", b.x, b.y, b.w, b.h);\n","\n","                #??\n","                int left = (b.x - b.w / 2.)*show_img->cols;\n","                int right = (b.x + b.w / 2.)*show_img->cols;\n","                int top = (b.y - b.h / 2.)*show_img->rows;\n","                int bot = (b.y + b.h / 2.)*show_img->rows;\n","\n","                if (left < 0) left = 0;\n","                if (right > show_img->cols - 1) right = show_img->cols - 1;\n","                if (top < 0) top = 0;\n","                if (bot > show_img->rows - 1) bot = show_img->rows - 1;\n","\n","                //int b_x_center = (left + right) / 2;\n","                //int b_y_center = (top + bot) / 2;\n","                //int b_width = right - left;\n","                //int b_height = bot - top;\n","                //sprintf(labelstr, \"%d x %d - w: %d, h: %d\", b_x_center, b_y_center, b_width, b_height);\n","\n","                /*add code(cutting image) start*/\n","            # 프레임이 125초 정도 지나고 정확도가 90이 넘고 객체 이름이 cow면 \n","        \t\tif(accur >= 90 && frame_id % 125 == 0 && strcmp(img_name,\"cow\")==0) {\n","        \t\t\t\n","        \t\t\tcv::Mat cutImage ; #이미지 저장\n","        \t\t\tcutImage = subImage(cv::Range(top, bot), cv::Range(left, right)) ; #이미지 자르기\n","        \n","        \t\t\tchar filename[100] ;\n","              # 파일 이름과 경로 저장\n","        \t\t\tsprintf(filename, \"/content/darknet/cut_video/%d-%s-%d.jpg\", frame_id, img_name, i) ;\n","        \t\t\t//file name and save point\n","        \t\t\t\n","        \t\t\timwrite(filename, cutImage) ; #자른 이미지 파일 저장\n","\n","              \n","              // label 텍스트 이름과 경로 저장\n","              char labelfilename[100] ;\n","              sprintf(labelfilename, \"/content/darknet/cut_label/%d-%s-%d.txt\", frame_id, img_name, i) ;\n","              // 텍스트 파일에 label 저장\n","              FILE *fp = fopen(labelfilename, \"w\");\n","  \t\t        fprintf(fp, \"0 %f %f %f %f\", bx, by, bw, bh);\n","  \t\t        fclose(fp);\n","        \t\t}\n","        \t\t/*add code end*/\n","\n","                float const font_size = show_img->rows / 1000.F;\n","                cv::Size const text_size = cv::getTextSize(labelstr, cv::FONT_HERSHEY_COMPLEX_SMALL, font_size, 1, 0);\n","                cv::Point pt1, pt2, pt_text, pt_text_bg1, pt_text_bg2;\n","                pt1.x = left;\n","                pt1.y = top;\n","                pt2.x = right;\n","                pt2.y = bot;\n","                pt_text.x = left;\n","                pt_text.y = top - 4;// 12;\n","                pt_text_bg1.x = left;\n","                pt_text_bg1.y = top - (3 + 18 * font_size);\n","                pt_text_bg2.x = right;\n","                if ((right - left) < text_size.width) pt_text_bg2.x = left + text_size.width;\n","                pt_text_bg2.y = top;\n","                cv::Scalar color;\n","                color.val[0] = red * 256;\n","                color.val[1] = green * 256;\n","                color.val[2] = blue * 256;\n","\n","                // you should create directory: result_img\n","                //static int copied_frame_id = -1;\n","                //static IplImage* copy_img = NULL;\n","                //if (copied_frame_id != frame_id) {\n","                //    copied_frame_id = frame_id;\n","                //    if(copy_img == NULL) copy_img = cvCreateImage(cvSize(show_img->width, show_img->height), show_img->depth, show_img->nChannels);\n","                //    cvCopy(show_img, copy_img, 0);\n","                //}\n","                //static int img_id = 0;\n","                //img_id++;\n","                //char image_name[1024];\n","                //sprintf(image_name, \"result_img/img_%d_%d_%d_%s.jpg\", frame_id, img_id, class_id, names[class_id]);\n","                //CvRect rect = cvRect(pt1.x, pt1.y, pt2.x - pt1.x, pt2.y - pt1.y);\n","                //cvSetImageROI(copy_img, rect);\n","                //cvSaveImage(image_name, copy_img, 0);\n","                //cvResetImageROI(copy_img);\n","\n","                cv::rectangle(*show_img, pt1, pt2, color, width, 8, 0);\n","                if (ext_output)\n","                    printf(\"\\t(left_x: %4.0f   top_y: %4.0f   width: %4.0f   height: %4.0f)\\n\",\n","                    (float)left, (float)top, b.w*show_img->cols, b.h*show_img->rows);\n","                else\n","                    printf(\"\\n\");\n","\n","                cv::rectangle(*show_img, pt_text_bg1, pt_text_bg2, color, width, 8, 0);\n","                cv::rectangle(*show_img, pt_text_bg1, pt_text_bg2, color, CV_FILLED, 8, 0);    // filled\n","                cv::Scalar black_color = CV_RGB(0, 0, 0);\n","                cv::putText(*show_img, labelstr, pt_text, cv::FONT_HERSHEY_COMPLEX_SMALL, font_size, black_color, 2 * font_size, CV_AA);\n","                // cv::FONT_HERSHEY_COMPLEX_SMALL, cv::FONT_HERSHEY_SIMPLEX\n","            }\n","        }\n","        if (ext_output) {\n","            fflush(stdout);\n","        }\n","    }\n","    catch (...) {\n","        cerr << \"OpenCV exception: draw_detections_cv_v3() \\n\";\n","    }\n","}"],"metadata":{"id":"h6gonCy0lOBu"},"execution_count":null,"outputs":[]}]}